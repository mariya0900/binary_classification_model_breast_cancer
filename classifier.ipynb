{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('data/data.csv')\n",
    "\n",
    "#dataset.columns = ['Id', 'Clump_thickness', 'Uniformity_cell_size', 'Uniformity_cell_shape', 'Marginal_adhesion', 'Single_e_cell_size', 'Bare_nuclei', 'Bland_chromatin', 'Normal_nucleoli', 'Mitoses', 'Class']\n",
    "\n",
    "dataset.head()\n",
    "#class column: 2 for benign, 4 for malignent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
       "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
       "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
       "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
       "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
       "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
       "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
       "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  ...  texture_worst  perimeter_worst   area_worst  \\\n",
       "count     569.000000  ...     569.000000       569.000000   569.000000   \n",
       "mean        0.181162  ...      25.677223       107.261213   880.583128   \n",
       "std         0.027414  ...       6.146258        33.602542   569.356993   \n",
       "min         0.106000  ...      12.020000        50.410000   185.200000   \n",
       "25%         0.161900  ...      21.080000        84.110000   515.300000   \n",
       "50%         0.179200  ...      25.410000        97.660000   686.500000   \n",
       "75%         0.195700  ...      29.720000       125.400000  1084.000000   \n",
       "max         0.304000  ...      49.540000       251.200000  4254.000000   \n",
       "\n",
       "       smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count        569.000000         569.000000       569.000000   \n",
       "mean           0.132369           0.254265         0.272188   \n",
       "std            0.022832           0.157336         0.208624   \n",
       "min            0.071170           0.027290         0.000000   \n",
       "25%            0.116600           0.147200         0.114500   \n",
       "50%            0.131300           0.211900         0.226700   \n",
       "75%            0.146000           0.339100         0.382900   \n",
       "max            0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
       "count            569.000000      569.000000               569.000000   \n",
       "mean               0.114606        0.290076                 0.083946   \n",
       "std                0.065732        0.061867                 0.018061   \n",
       "min                0.000000        0.156500                 0.055040   \n",
       "25%                0.064930        0.250400                 0.071460   \n",
       "50%                0.099930        0.282200                 0.080040   \n",
       "75%                0.161400        0.317900                 0.092080   \n",
       "max                0.291000        0.663800                 0.207500   \n",
       "\n",
       "       Unnamed: 32  \n",
       "count          0.0  \n",
       "mean           NaN  \n",
       "std            NaN  \n",
       "min            NaN  \n",
       "25%            NaN  \n",
       "50%            NaN  \n",
       "75%            NaN  \n",
       "max            NaN  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         False\n",
       "diagnosis                  False\n",
       "radius_mean                False\n",
       "texture_mean               False\n",
       "perimeter_mean             False\n",
       "area_mean                  False\n",
       "smoothness_mean            False\n",
       "compactness_mean           False\n",
       "concavity_mean             False\n",
       "concave points_mean        False\n",
       "symmetry_mean              False\n",
       "fractal_dimension_mean     False\n",
       "radius_se                  False\n",
       "texture_se                 False\n",
       "perimeter_se               False\n",
       "area_se                    False\n",
       "smoothness_se              False\n",
       "compactness_se             False\n",
       "concavity_se               False\n",
       "concave points_se          False\n",
       "symmetry_se                False\n",
       "fractal_dimension_se       False\n",
       "radius_worst               False\n",
       "texture_worst              False\n",
       "perimeter_worst            False\n",
       "area_worst                 False\n",
       "smoothness_worst           False\n",
       "compactness_worst          False\n",
       "concavity_worst            False\n",
       "concave points_worst       False\n",
       "symmetry_worst             False\n",
       "fractal_dimension_worst    False\n",
       "Unnamed: 32                 True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().any() # seeing which columns have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 32'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns[dataset.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Unnamed: 32'].isnull().count() # how many null values are in column Unnamed: 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns = 'Unnamed: 32', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  0  Null Values is the Dataset\n"
     ]
    }
   ],
   "source": [
    "print(f'There are ',dataset.isnull().values.sum(), ' Null Values is the Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      M\n",
       "1      M\n",
       "2      M\n",
       "3      M\n",
       "4      M\n",
       "      ..\n",
       "564    M\n",
       "565    M\n",
       "566    M\n",
       "567    M\n",
       "568    B\n",
       "Name: diagnosis, Length: 569, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dataset.drop(columns = ['diagnosis', 'id'])\n",
    "#print(x)\n",
    "y = dataset['diagnosis']\n",
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the target column contains strings, we need to convert them to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [1 if i =='M' else 0 for i in y]\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (455, 30)\n",
      "y_train (455, 1)\n",
      "x_test (114, 30)\n",
      "y_test (114, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#with random_state=0, we get the same train and test sets across other executions\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=0)\n",
    "print(f'x_train',x_train.shape) \n",
    "print(f'y_train',y_train.shape)  \n",
    "print(f'x_test',x_test.shape)   \n",
    "print(f'y_test',y_test.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "#we calculate the mean and standard deviation of each feature/column based on the training data. Then, we use these mean and standard deviation values to scale the training data.\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "#perform standartization by centering and scaling\n",
    "x_test = scaler.transform(x_test)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ONE WAY TO CHANGE DIM\n",
    "import numpy as np\n",
    "XQ = np.expand_dims(x_train, -1)\n",
    "XQ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANOTHER WAY\n",
    "x_train = np.reshape( x_train , ( x_train.shape[0] , 30 , 1 )  )\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train = y_train.to_numpy()\n",
    "#y_train.reshape(y_train.shape[0], y_train.shape[1], 1)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 128)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = (4, 10, 128)\n",
    "inp_n = inp[1:]\n",
    "inp_n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model - Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 1s 22ms/step - loss: 0.6597 - accuracy: 0.6549 - precision: 0.6053 - recall: 0.1394 - val_loss: 0.6083 - val_accuracy: 0.8158 - val_precision: 0.9062 - val_recall: 0.6170\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.5532 - accuracy: 0.8132 - precision: 1.0000 - recall: 0.4848 - val_loss: 0.5191 - val_accuracy: 0.8684 - val_precision: 0.9444 - val_recall: 0.7234\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4618 - accuracy: 0.8725 - precision: 0.9820 - recall: 0.6606 - val_loss: 0.4334 - val_accuracy: 0.9035 - val_precision: 0.9500 - val_recall: 0.8085\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3760 - accuracy: 0.8945 - precision: 0.9680 - recall: 0.7333 - val_loss: 0.3603 - val_accuracy: 0.9298 - val_precision: 0.9535 - val_recall: 0.8723\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3101 - accuracy: 0.9187 - precision: 0.9848 - recall: 0.7879 - val_loss: 0.3005 - val_accuracy: 0.9211 - val_precision: 0.9318 - val_recall: 0.8723\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2560 - accuracy: 0.9187 - precision: 0.9571 - recall: 0.8121 - val_loss: 0.2528 - val_accuracy: 0.9211 - val_precision: 0.9130 - val_recall: 0.8936\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2054 - accuracy: 0.9385 - precision: 0.9790 - recall: 0.8485 - val_loss: 0.2161 - val_accuracy: 0.9386 - val_precision: 0.9545 - val_recall: 0.8936\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1873 - accuracy: 0.9363 - precision: 0.9658 - recall: 0.8545 - val_loss: 0.1895 - val_accuracy: 0.9298 - val_precision: 0.9535 - val_recall: 0.8723\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1577 - accuracy: 0.9560 - precision: 0.9677 - recall: 0.9091 - val_loss: 0.1724 - val_accuracy: 0.9123 - val_precision: 0.9111 - val_recall: 0.8723\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1425 - accuracy: 0.9495 - precision: 0.9610 - recall: 0.8970 - val_loss: 0.1529 - val_accuracy: 0.9386 - val_precision: 0.9545 - val_recall: 0.8936\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1327 - accuracy: 0.9626 - precision: 0.9744 - recall: 0.9212 - val_loss: 0.1407 - val_accuracy: 0.9386 - val_precision: 0.9545 - val_recall: 0.8936\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1245 - accuracy: 0.9626 - precision: 0.9625 - recall: 0.9333 - val_loss: 0.1308 - val_accuracy: 0.9474 - val_precision: 0.9556 - val_recall: 0.9149\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1161 - accuracy: 0.9626 - precision: 0.9684 - recall: 0.9273 - val_loss: 0.1221 - val_accuracy: 0.9474 - val_precision: 0.9556 - val_recall: 0.9149\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1131 - accuracy: 0.9692 - precision: 0.9809 - recall: 0.9333 - val_loss: 0.1161 - val_accuracy: 0.9474 - val_precision: 0.9556 - val_recall: 0.9149\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1040 - accuracy: 0.9626 - precision: 0.9684 - recall: 0.9273 - val_loss: 0.1108 - val_accuracy: 0.9561 - val_precision: 0.9565 - val_recall: 0.9362\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0931 - accuracy: 0.9670 - precision: 0.9688 - recall: 0.9394 - val_loss: 0.1084 - val_accuracy: 0.9561 - val_precision: 0.9565 - val_recall: 0.9362\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0967 - accuracy: 0.9692 - precision: 0.9632 - recall: 0.9515 - val_loss: 0.1041 - val_accuracy: 0.9561 - val_precision: 0.9565 - val_recall: 0.9362\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0920 - accuracy: 0.9670 - precision: 0.9688 - recall: 0.9394 - val_loss: 0.1023 - val_accuracy: 0.9561 - val_precision: 0.9565 - val_recall: 0.9362\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0885 - accuracy: 0.9714 - precision: 0.9578 - recall: 0.9636 - val_loss: 0.0985 - val_accuracy: 0.9561 - val_precision: 0.9565 - val_recall: 0.9362\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0846 - accuracy: 0.9736 - precision: 0.9752 - recall: 0.9515 - val_loss: 0.0936 - val_accuracy: 0.9474 - val_precision: 0.9362 - val_recall: 0.9362\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0882 - accuracy: 0.9692 - precision: 0.9748 - recall: 0.9394 - val_loss: 0.0901 - val_accuracy: 0.9474 - val_precision: 0.9362 - val_recall: 0.9362\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0868 - accuracy: 0.9736 - precision: 0.9752 - recall: 0.9515 - val_loss: 0.0949 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0785 - accuracy: 0.9714 - precision: 0.9634 - recall: 0.9576 - val_loss: 0.0898 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0766 - accuracy: 0.9758 - precision: 0.9812 - recall: 0.9515 - val_loss: 0.0877 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0774 - accuracy: 0.9714 - precision: 0.9691 - recall: 0.9515 - val_loss: 0.0860 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0787 - accuracy: 0.9714 - precision: 0.9750 - recall: 0.9455 - val_loss: 0.0873 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0717 - accuracy: 0.9758 - precision: 0.9753 - recall: 0.9576 - val_loss: 0.0861 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0667 - accuracy: 0.9736 - precision: 0.9636 - recall: 0.9636 - val_loss: 0.0834 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0761 - accuracy: 0.9758 - precision: 0.9753 - recall: 0.9576 - val_loss: 0.0827 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0771 - accuracy: 0.9736 - precision: 0.9752 - recall: 0.9515 - val_loss: 0.0861 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0763 - accuracy: 0.9736 - precision: 0.9636 - recall: 0.9636 - val_loss: 0.0846 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0669 - accuracy: 0.9758 - precision: 0.9695 - recall: 0.9636 - val_loss: 0.0863 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0698 - accuracy: 0.9780 - precision: 0.9755 - recall: 0.9636 - val_loss: 0.0840 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0715 - accuracy: 0.9692 - precision: 0.9632 - recall: 0.9515 - val_loss: 0.0843 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0740 - accuracy: 0.9692 - precision: 0.9689 - recall: 0.9455 - val_loss: 0.0851 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0728 - accuracy: 0.9736 - precision: 0.9636 - recall: 0.9636 - val_loss: 0.0831 - val_accuracy: 0.9474 - val_precision: 0.9362 - val_recall: 0.9362\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0611 - accuracy: 0.9802 - precision: 0.9756 - recall: 0.9697 - val_loss: 0.0833 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0638 - accuracy: 0.9802 - precision: 0.9756 - recall: 0.9697 - val_loss: 0.0896 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0621 - accuracy: 0.9736 - precision: 0.9693 - recall: 0.9576 - val_loss: 0.0842 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0606 - accuracy: 0.9824 - precision: 0.9758 - recall: 0.9758 - val_loss: 0.0815 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0754 - accuracy: 0.9758 - precision: 0.9812 - recall: 0.9515 - val_loss: 0.0848 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0611 - accuracy: 0.9802 - precision: 0.9756 - recall: 0.9697 - val_loss: 0.0870 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0620 - accuracy: 0.9780 - precision: 0.9755 - recall: 0.9636 - val_loss: 0.0883 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0590 - accuracy: 0.9780 - precision: 0.9755 - recall: 0.9636 - val_loss: 0.0847 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0663 - accuracy: 0.9714 - precision: 0.9691 - recall: 0.9515 - val_loss: 0.0846 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0596 - accuracy: 0.9824 - precision: 0.9816 - recall: 0.9697 - val_loss: 0.0835 - val_accuracy: 0.9474 - val_precision: 0.9362 - val_recall: 0.9362\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0606 - accuracy: 0.9758 - precision: 0.9753 - recall: 0.9576 - val_loss: 0.0859 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0592 - accuracy: 0.9780 - precision: 0.9755 - recall: 0.9636 - val_loss: 0.0869 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0641 - accuracy: 0.9758 - precision: 0.9695 - recall: 0.9636 - val_loss: 0.0868 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0587 - accuracy: 0.9846 - precision: 0.9877 - recall: 0.9697 - val_loss: 0.0855 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0608 - accuracy: 0.9802 - precision: 0.9875 - recall: 0.9576 - val_loss: 0.0860 - val_accuracy: 0.9474 - val_precision: 0.9362 - val_recall: 0.9362\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0575 - accuracy: 0.9758 - precision: 0.9873 - recall: 0.9455 - val_loss: 0.0854 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0581 - accuracy: 0.9824 - precision: 0.9816 - recall: 0.9697 - val_loss: 0.0831 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0531 - accuracy: 0.9824 - precision: 0.9816 - recall: 0.9697 - val_loss: 0.0822 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0507 - accuracy: 0.9846 - precision: 0.9937 - recall: 0.9636 - val_loss: 0.0843 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0521 - accuracy: 0.9802 - precision: 0.9756 - recall: 0.9697 - val_loss: 0.0835 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0508 - accuracy: 0.9868 - precision: 0.9938 - recall: 0.9697 - val_loss: 0.0838 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0556 - accuracy: 0.9802 - precision: 0.9815 - recall: 0.9636 - val_loss: 0.0820 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0465 - accuracy: 0.9846 - precision: 0.9817 - recall: 0.9758 - val_loss: 0.0820 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0517 - accuracy: 0.9802 - precision: 0.9815 - recall: 0.9636 - val_loss: 0.0839 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0439 - accuracy: 0.9824 - precision: 0.9816 - recall: 0.9697 - val_loss: 0.0843 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0451 - accuracy: 0.9824 - precision: 0.9816 - recall: 0.9697 - val_loss: 0.0822 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0437 - accuracy: 0.9802 - precision: 0.9815 - recall: 0.9636 - val_loss: 0.0826 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0508 - accuracy: 0.9802 - precision: 0.9815 - recall: 0.9636 - val_loss: 0.0826 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0471 - accuracy: 0.9824 - precision: 0.9758 - recall: 0.9758 - val_loss: 0.0830 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0507 - accuracy: 0.9802 - precision: 0.9875 - recall: 0.9576 - val_loss: 0.0845 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0472 - accuracy: 0.9846 - precision: 0.9937 - recall: 0.9636 - val_loss: 0.0895 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0507 - accuracy: 0.9802 - precision: 0.9756 - recall: 0.9697 - val_loss: 0.0811 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0519 - accuracy: 0.9846 - precision: 0.9817 - recall: 0.9758 - val_loss: 0.0858 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0511 - accuracy: 0.9824 - precision: 0.9816 - recall: 0.9697 - val_loss: 0.0836 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0455 - accuracy: 0.9824 - precision: 0.9876 - recall: 0.9636 - val_loss: 0.0893 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0404 - accuracy: 0.9890 - precision: 0.9878 - recall: 0.9818 - val_loss: 0.0883 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0457 - accuracy: 0.9802 - precision: 0.9815 - recall: 0.9636 - val_loss: 0.0880 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0374 - accuracy: 0.9846 - precision: 0.9817 - recall: 0.9758 - val_loss: 0.0854 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0456 - accuracy: 0.9802 - precision: 0.9875 - recall: 0.9576 - val_loss: 0.0850 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0413 - accuracy: 0.9868 - precision: 0.9877 - recall: 0.9758 - val_loss: 0.0892 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0438 - accuracy: 0.9802 - precision: 0.9699 - recall: 0.9758 - val_loss: 0.0884 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0389 - accuracy: 0.9890 - precision: 0.9878 - recall: 0.9818 - val_loss: 0.0863 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0410 - accuracy: 0.9868 - precision: 0.9938 - recall: 0.9697 - val_loss: 0.0853 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0434 - accuracy: 0.9846 - precision: 0.9877 - recall: 0.9697 - val_loss: 0.0819 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0430 - accuracy: 0.9868 - precision: 0.9818 - recall: 0.9818 - val_loss: 0.0905 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0362 - accuracy: 0.9890 - precision: 1.0000 - recall: 0.9697 - val_loss: 0.0834 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0451 - accuracy: 0.9890 - precision: 0.9938 - recall: 0.9758 - val_loss: 0.0834 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0316 - accuracy: 0.9912 - precision: 0.9879 - recall: 0.9879 - val_loss: 0.0821 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0379 - accuracy: 0.9912 - precision: 0.9939 - recall: 0.9818 - val_loss: 0.0815 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0372 - accuracy: 0.9890 - precision: 1.0000 - recall: 0.9697 - val_loss: 0.0850 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0367 - accuracy: 0.9912 - precision: 0.9939 - recall: 0.9818 - val_loss: 0.0857 - val_accuracy: 0.9649 - val_precision: 0.9388 - val_recall: 0.9787\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0313 - accuracy: 0.9912 - precision: 0.9939 - recall: 0.9818 - val_loss: 0.0854 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0365 - accuracy: 0.9868 - precision: 0.9938 - recall: 0.9697 - val_loss: 0.0855 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0383 - accuracy: 0.9824 - precision: 0.9758 - recall: 0.9758 - val_loss: 0.0961 - val_accuracy: 0.9649 - val_precision: 0.9388 - val_recall: 0.9787\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0371 - accuracy: 0.9868 - precision: 0.9877 - recall: 0.9758 - val_loss: 0.0820 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0363 - accuracy: 0.9890 - precision: 0.9938 - recall: 0.9758 - val_loss: 0.0787 - val_accuracy: 0.9649 - val_precision: 0.9388 - val_recall: 0.9787\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0316 - accuracy: 0.9934 - precision: 1.0000 - recall: 0.9818 - val_loss: 0.0771 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0343 - accuracy: 0.9846 - precision: 0.9877 - recall: 0.9697 - val_loss: 0.0762 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0417 - accuracy: 0.9846 - precision: 0.9817 - recall: 0.9758 - val_loss: 0.0768 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0313 - accuracy: 0.9912 - precision: 1.0000 - recall: 0.9758 - val_loss: 0.0733 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0317 - accuracy: 0.9912 - precision: 1.0000 - recall: 0.9758 - val_loss: 0.0912 - val_accuracy: 0.9649 - val_precision: 0.9388 - val_recall: 0.9787\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0287 - accuracy: 0.9956 - precision: 1.0000 - recall: 0.9879 - val_loss: 0.0933 - val_accuracy: 0.9649 - val_precision: 0.9388 - val_recall: 0.9787\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0369 - accuracy: 0.9868 - precision: 0.9818 - recall: 0.9818 - val_loss: 0.0811 - val_accuracy: 0.9649 - val_precision: 0.9388 - val_recall: 0.9787\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0310 - accuracy: 0.9934 - precision: 1.0000 - recall: 0.9818 - val_loss: 0.0790 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_19 (Conv1D)          (None, 28, 168)           672       \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 28, 168)           0         \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (None, 14, 168)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_20 (Conv1D)          (None, 12, 64)            32320     \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPoolin  (None, 6, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 128)               49280     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 90,593\n",
      "Trainable params: 90,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#The output of the Conv1D layer will have a shape of (batch_size, num_filters, output_dim). Since the output of the Conv1D layer is still in a multi-dimensional format, it cannot be directly connected to the subsequent Dense layers which expect one-dimensional input.\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(168, kernel_size = 3, input_shape = (30, 1) ), #Covolution1D operates on (batch size, length, channels)\n",
    "\n",
    "    tf.keras.layers.MaxPool1D(2),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Conv1D(64, kernel_size = 3), \n",
    "    tf.keras.layers.MaxPool1D(2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    \n",
    "    #tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    #tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "    #tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "])\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.binary_crossentropy,\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "    metrics = [\n",
    "        tf.keras.metrics.BinaryAccuracy(name = 'accuracy'),\n",
    "        tf.keras.metrics.Precision(name = 'precision'),\n",
    "        tf.keras.metrics.Recall(name = 'recall')\n",
    "    ]\n",
    ")\n",
    "validation_data=(x_test,y_test)\n",
    "history = model.fit(x_train, y_train,  epochs = 100, validation_data=validation_data)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot the results\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
