{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('data/data.csv')\n",
    "\n",
    "#dataset.columns = ['Id', 'Clump_thickness', 'Uniformity_cell_size', 'Uniformity_cell_shape', 'Marginal_adhesion', 'Single_e_cell_size', 'Bare_nuclei', 'Bland_chromatin', 'Normal_nucleoli', 'Mitoses', 'Class']\n",
    "\n",
    "dataset.head()\n",
    "#class column: 2 for benign, 4 for malignent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
       "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
       "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
       "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
       "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
       "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
       "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
       "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  ...  texture_worst  perimeter_worst   area_worst  \\\n",
       "count     569.000000  ...     569.000000       569.000000   569.000000   \n",
       "mean        0.181162  ...      25.677223       107.261213   880.583128   \n",
       "std         0.027414  ...       6.146258        33.602542   569.356993   \n",
       "min         0.106000  ...      12.020000        50.410000   185.200000   \n",
       "25%         0.161900  ...      21.080000        84.110000   515.300000   \n",
       "50%         0.179200  ...      25.410000        97.660000   686.500000   \n",
       "75%         0.195700  ...      29.720000       125.400000  1084.000000   \n",
       "max         0.304000  ...      49.540000       251.200000  4254.000000   \n",
       "\n",
       "       smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count        569.000000         569.000000       569.000000   \n",
       "mean           0.132369           0.254265         0.272188   \n",
       "std            0.022832           0.157336         0.208624   \n",
       "min            0.071170           0.027290         0.000000   \n",
       "25%            0.116600           0.147200         0.114500   \n",
       "50%            0.131300           0.211900         0.226700   \n",
       "75%            0.146000           0.339100         0.382900   \n",
       "max            0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
       "count            569.000000      569.000000               569.000000   \n",
       "mean               0.114606        0.290076                 0.083946   \n",
       "std                0.065732        0.061867                 0.018061   \n",
       "min                0.000000        0.156500                 0.055040   \n",
       "25%                0.064930        0.250400                 0.071460   \n",
       "50%                0.099930        0.282200                 0.080040   \n",
       "75%                0.161400        0.317900                 0.092080   \n",
       "max                0.291000        0.663800                 0.207500   \n",
       "\n",
       "       Unnamed: 32  \n",
       "count          0.0  \n",
       "mean           NaN  \n",
       "std            NaN  \n",
       "min            NaN  \n",
       "25%            NaN  \n",
       "50%            NaN  \n",
       "75%            NaN  \n",
       "max            NaN  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         False\n",
       "diagnosis                  False\n",
       "radius_mean                False\n",
       "texture_mean               False\n",
       "perimeter_mean             False\n",
       "area_mean                  False\n",
       "smoothness_mean            False\n",
       "compactness_mean           False\n",
       "concavity_mean             False\n",
       "concave points_mean        False\n",
       "symmetry_mean              False\n",
       "fractal_dimension_mean     False\n",
       "radius_se                  False\n",
       "texture_se                 False\n",
       "perimeter_se               False\n",
       "area_se                    False\n",
       "smoothness_se              False\n",
       "compactness_se             False\n",
       "concavity_se               False\n",
       "concave points_se          False\n",
       "symmetry_se                False\n",
       "fractal_dimension_se       False\n",
       "radius_worst               False\n",
       "texture_worst              False\n",
       "perimeter_worst            False\n",
       "area_worst                 False\n",
       "smoothness_worst           False\n",
       "compactness_worst          False\n",
       "concavity_worst            False\n",
       "concave points_worst       False\n",
       "symmetry_worst             False\n",
       "fractal_dimension_worst    False\n",
       "Unnamed: 32                 True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().any() # seeing which columns have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 32'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns[dataset.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Unnamed: 32'].isnull().count() # how many null values are in column Unnamed: 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns = 'Unnamed: 32', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  0  Null Values is the Dataset\n"
     ]
    }
   ],
   "source": [
    "print(f'There are ',dataset.isnull().values.sum(), ' Null Values is the Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      M\n",
       "1      M\n",
       "2      M\n",
       "3      M\n",
       "4      M\n",
       "      ..\n",
       "564    M\n",
       "565    M\n",
       "566    M\n",
       "567    M\n",
       "568    B\n",
       "Name: diagnosis, Length: 569, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dataset.drop(columns = ['diagnosis', 'id'])\n",
    "#print(x)\n",
    "y = dataset['diagnosis']\n",
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the target column contains strings, we need to convert them to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [1 if i =='M' else 0 for i in y]\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (455, 30)\n",
      "y_train (455, 1)\n",
      "x_test (114, 30)\n",
      "y_test (114, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#with random_state=0, we get the same train and test sets across other executions\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=0)\n",
    "print(f'x_train',x_train.shape) \n",
    "print(f'y_train',y_train.shape)  \n",
    "print(f'x_test',x_test.shape)   \n",
    "print(f'y_test',y_test.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "#we calculate the mean and standard deviation of each feature/column based on the training data. Then, we use these mean and standard deviation values to scale the training data.\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "#perform standartization by centering and scaling\n",
    "x_test = scaler.transform(x_test)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ONE WAY TO CHANGE DIM\n",
    "import numpy as np\n",
    "XQ = np.expand_dims(x_train, -1)\n",
    "XQ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANOTHER WAY\n",
    "x_train = np.reshape( x_train , ( x_train.shape[0] , 30 , 1 )  )\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train = y_train.to_numpy()\n",
    "#y_train.reshape(y_train.shape[0], y_train.shape[1], 1)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 128)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = (4, 10, 128)\n",
    "inp_n = inp[1:]\n",
    "inp_n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model - Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 2s 29ms/step - loss: 0.6703 - accuracy: 0.6527 - precision: 0.6129 - recall: 0.1152 - val_loss: 0.5938 - val_accuracy: 0.8333 - val_precision: 0.9118 - val_recall: 0.6596\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5466 - accuracy: 0.8527 - precision: 0.9298 - recall: 0.6424 - val_loss: 0.4904 - val_accuracy: 0.8947 - val_precision: 0.8889 - val_recall: 0.8511\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4339 - accuracy: 0.9099 - precision: 0.9429 - recall: 0.8000 - val_loss: 0.3983 - val_accuracy: 0.9123 - val_precision: 0.8936 - val_recall: 0.8936\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3437 - accuracy: 0.9099 - precision: 0.9366 - recall: 0.8061 - val_loss: 0.3246 - val_accuracy: 0.9386 - val_precision: 0.9545 - val_recall: 0.8936\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2782 - accuracy: 0.9143 - precision: 0.9315 - recall: 0.8242 - val_loss: 0.2736 - val_accuracy: 0.9386 - val_precision: 0.9545 - val_recall: 0.8936\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2326 - accuracy: 0.9319 - precision: 0.9589 - recall: 0.8485 - val_loss: 0.2378 - val_accuracy: 0.9298 - val_precision: 0.9535 - val_recall: 0.8723\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1951 - accuracy: 0.9363 - precision: 0.9658 - recall: 0.8545 - val_loss: 0.2095 - val_accuracy: 0.9298 - val_precision: 0.9535 - val_recall: 0.8723\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1691 - accuracy: 0.9429 - precision: 0.9664 - recall: 0.8727 - val_loss: 0.1863 - val_accuracy: 0.9298 - val_precision: 0.9535 - val_recall: 0.8723\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1510 - accuracy: 0.9495 - precision: 0.9733 - recall: 0.8848 - val_loss: 0.1671 - val_accuracy: 0.9386 - val_precision: 0.9762 - val_recall: 0.8723\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1349 - accuracy: 0.9560 - precision: 0.9739 - recall: 0.9030 - val_loss: 0.1531 - val_accuracy: 0.9386 - val_precision: 0.9762 - val_recall: 0.8723\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1227 - accuracy: 0.9604 - precision: 0.9742 - recall: 0.9152 - val_loss: 0.1415 - val_accuracy: 0.9474 - val_precision: 0.9767 - val_recall: 0.8936\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1149 - accuracy: 0.9604 - precision: 0.9682 - recall: 0.9212 - val_loss: 0.1333 - val_accuracy: 0.9474 - val_precision: 0.9767 - val_recall: 0.8936\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1075 - accuracy: 0.9670 - precision: 0.9747 - recall: 0.9333 - val_loss: 0.1251 - val_accuracy: 0.9561 - val_precision: 0.9773 - val_recall: 0.9149\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1001 - accuracy: 0.9670 - precision: 0.9688 - recall: 0.9394 - val_loss: 0.1179 - val_accuracy: 0.9561 - val_precision: 0.9773 - val_recall: 0.9149\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1021 - accuracy: 0.9648 - precision: 0.9571 - recall: 0.9455 - val_loss: 0.1144 - val_accuracy: 0.9386 - val_precision: 0.9348 - val_recall: 0.9149\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0961 - accuracy: 0.9714 - precision: 0.9750 - recall: 0.9455 - val_loss: 0.1088 - val_accuracy: 0.9649 - val_precision: 1.0000 - val_recall: 0.9149\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0906 - accuracy: 0.9736 - precision: 0.9811 - recall: 0.9455 - val_loss: 0.1038 - val_accuracy: 0.9649 - val_precision: 1.0000 - val_recall: 0.9149\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0875 - accuracy: 0.9692 - precision: 0.9689 - recall: 0.9455 - val_loss: 0.1001 - val_accuracy: 0.9561 - val_precision: 0.9773 - val_recall: 0.9149\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0786 - accuracy: 0.9736 - precision: 0.9693 - recall: 0.9576 - val_loss: 0.0964 - val_accuracy: 0.9561 - val_precision: 0.9773 - val_recall: 0.9149\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0844 - accuracy: 0.9692 - precision: 0.9632 - recall: 0.9515 - val_loss: 0.0942 - val_accuracy: 0.9561 - val_precision: 0.9773 - val_recall: 0.9149\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0832 - accuracy: 0.9692 - precision: 0.9809 - recall: 0.9333 - val_loss: 0.0927 - val_accuracy: 0.9649 - val_precision: 1.0000 - val_recall: 0.9149\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0801 - accuracy: 0.9736 - precision: 0.9693 - recall: 0.9576 - val_loss: 0.0969 - val_accuracy: 0.9561 - val_precision: 0.9565 - val_recall: 0.9362\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0800 - accuracy: 0.9692 - precision: 0.9632 - recall: 0.9515 - val_loss: 0.0926 - val_accuracy: 0.9474 - val_precision: 0.9556 - val_recall: 0.9149\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0726 - accuracy: 0.9802 - precision: 0.9756 - recall: 0.9697 - val_loss: 0.0907 - val_accuracy: 0.9474 - val_precision: 0.9556 - val_recall: 0.9149\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0704 - accuracy: 0.9780 - precision: 0.9755 - recall: 0.9636 - val_loss: 0.0877 - val_accuracy: 0.9474 - val_precision: 0.9556 - val_recall: 0.9149\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0740 - accuracy: 0.9758 - precision: 0.9753 - recall: 0.9576 - val_loss: 0.0880 - val_accuracy: 0.9561 - val_precision: 0.9773 - val_recall: 0.9149\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0733 - accuracy: 0.9714 - precision: 0.9634 - recall: 0.9576 - val_loss: 0.0866 - val_accuracy: 0.9561 - val_precision: 0.9565 - val_recall: 0.9362\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0692 - accuracy: 0.9758 - precision: 0.9695 - recall: 0.9636 - val_loss: 0.0866 - val_accuracy: 0.9561 - val_precision: 0.9565 - val_recall: 0.9362\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0729 - accuracy: 0.9714 - precision: 0.9691 - recall: 0.9515 - val_loss: 0.0832 - val_accuracy: 0.9561 - val_precision: 0.9565 - val_recall: 0.9362\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0707 - accuracy: 0.9802 - precision: 0.9875 - recall: 0.9576 - val_loss: 0.0836 - val_accuracy: 0.9561 - val_precision: 0.9565 - val_recall: 0.9362\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0691 - accuracy: 0.9758 - precision: 0.9695 - recall: 0.9636 - val_loss: 0.0884 - val_accuracy: 0.9561 - val_precision: 0.9565 - val_recall: 0.9362\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0700 - accuracy: 0.9780 - precision: 0.9814 - recall: 0.9576 - val_loss: 0.0855 - val_accuracy: 0.9649 - val_precision: 0.9778 - val_recall: 0.9362\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0689 - accuracy: 0.9714 - precision: 0.9634 - recall: 0.9576 - val_loss: 0.0856 - val_accuracy: 0.9561 - val_precision: 0.9565 - val_recall: 0.9362\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0651 - accuracy: 0.9758 - precision: 0.9753 - recall: 0.9576 - val_loss: 0.0857 - val_accuracy: 0.9561 - val_precision: 0.9565 - val_recall: 0.9362\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0640 - accuracy: 0.9758 - precision: 0.9753 - recall: 0.9576 - val_loss: 0.0838 - val_accuracy: 0.9561 - val_precision: 0.9565 - val_recall: 0.9362\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0608 - accuracy: 0.9780 - precision: 0.9814 - recall: 0.9576 - val_loss: 0.0849 - val_accuracy: 0.9561 - val_precision: 0.9565 - val_recall: 0.9362\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0602 - accuracy: 0.9802 - precision: 0.9756 - recall: 0.9697 - val_loss: 0.0847 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0664 - accuracy: 0.9758 - precision: 0.9695 - recall: 0.9636 - val_loss: 0.0838 - val_accuracy: 0.9649 - val_precision: 0.9778 - val_recall: 0.9362\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0595 - accuracy: 0.9802 - precision: 0.9875 - recall: 0.9576 - val_loss: 0.0807 - val_accuracy: 0.9649 - val_precision: 0.9778 - val_recall: 0.9362\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0610 - accuracy: 0.9758 - precision: 0.9753 - recall: 0.9576 - val_loss: 0.0817 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0606 - accuracy: 0.9736 - precision: 0.9636 - recall: 0.9636 - val_loss: 0.0809 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0592 - accuracy: 0.9736 - precision: 0.9636 - recall: 0.9636 - val_loss: 0.0813 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0581 - accuracy: 0.9758 - precision: 0.9753 - recall: 0.9576 - val_loss: 0.0799 - val_accuracy: 0.9649 - val_precision: 0.9778 - val_recall: 0.9362\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0574 - accuracy: 0.9802 - precision: 0.9756 - recall: 0.9697 - val_loss: 0.0787 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0578 - accuracy: 0.9824 - precision: 0.9816 - recall: 0.9697 - val_loss: 0.0786 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0581 - accuracy: 0.9802 - precision: 0.9756 - recall: 0.9697 - val_loss: 0.0769 - val_accuracy: 0.9649 - val_precision: 0.9778 - val_recall: 0.9362\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0564 - accuracy: 0.9824 - precision: 0.9876 - recall: 0.9636 - val_loss: 0.0709 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0561 - accuracy: 0.9802 - precision: 0.9756 - recall: 0.9697 - val_loss: 0.0700 - val_accuracy: 0.9561 - val_precision: 0.9565 - val_recall: 0.9362\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0625 - accuracy: 0.9758 - precision: 0.9812 - recall: 0.9515 - val_loss: 0.0704 - val_accuracy: 0.9649 - val_precision: 0.9778 - val_recall: 0.9362\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0517 - accuracy: 0.9846 - precision: 0.9877 - recall: 0.9697 - val_loss: 0.0733 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0541 - accuracy: 0.9802 - precision: 0.9756 - recall: 0.9697 - val_loss: 0.0714 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0607 - accuracy: 0.9736 - precision: 0.9752 - recall: 0.9515 - val_loss: 0.0765 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0525 - accuracy: 0.9824 - precision: 0.9876 - recall: 0.9636 - val_loss: 0.0751 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0545 - accuracy: 0.9802 - precision: 0.9875 - recall: 0.9576 - val_loss: 0.0734 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0570 - accuracy: 0.9758 - precision: 0.9753 - recall: 0.9576 - val_loss: 0.0712 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0552 - accuracy: 0.9802 - precision: 0.9756 - recall: 0.9697 - val_loss: 0.0824 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0515 - accuracy: 0.9846 - precision: 0.9877 - recall: 0.9697 - val_loss: 0.0772 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0498 - accuracy: 0.9868 - precision: 0.9938 - recall: 0.9697 - val_loss: 0.0774 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0485 - accuracy: 0.9846 - precision: 0.9817 - recall: 0.9758 - val_loss: 0.0754 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0463 - accuracy: 0.9868 - precision: 0.9938 - recall: 0.9697 - val_loss: 0.0772 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0462 - accuracy: 0.9846 - precision: 0.9877 - recall: 0.9697 - val_loss: 0.0791 - val_accuracy: 0.9649 - val_precision: 0.9778 - val_recall: 0.9362\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0428 - accuracy: 0.9846 - precision: 0.9877 - recall: 0.9697 - val_loss: 0.0783 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0477 - accuracy: 0.9824 - precision: 0.9816 - recall: 0.9697 - val_loss: 0.0780 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0473 - accuracy: 0.9824 - precision: 0.9816 - recall: 0.9697 - val_loss: 0.0817 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0412 - accuracy: 0.9846 - precision: 0.9877 - recall: 0.9697 - val_loss: 0.0795 - val_accuracy: 0.9737 - val_precision: 0.9783 - val_recall: 0.9574\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0501 - accuracy: 0.9802 - precision: 0.9815 - recall: 0.9636 - val_loss: 0.0761 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0424 - accuracy: 0.9890 - precision: 0.9938 - recall: 0.9758 - val_loss: 0.0813 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0428 - accuracy: 0.9868 - precision: 0.9938 - recall: 0.9697 - val_loss: 0.0813 - val_accuracy: 0.9737 - val_precision: 0.9783 - val_recall: 0.9574\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0405 - accuracy: 0.9846 - precision: 0.9877 - recall: 0.9697 - val_loss: 0.0775 - val_accuracy: 0.9737 - val_precision: 0.9783 - val_recall: 0.9574\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0476 - accuracy: 0.9736 - precision: 0.9636 - recall: 0.9636 - val_loss: 0.0819 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0454 - accuracy: 0.9802 - precision: 0.9815 - recall: 0.9636 - val_loss: 0.0854 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0435 - accuracy: 0.9824 - precision: 0.9876 - recall: 0.9636 - val_loss: 0.0869 - val_accuracy: 0.9737 - val_precision: 0.9783 - val_recall: 0.9574\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0384 - accuracy: 0.9846 - precision: 0.9877 - recall: 0.9697 - val_loss: 0.0805 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0466 - accuracy: 0.9846 - precision: 0.9877 - recall: 0.9697 - val_loss: 0.0771 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0395 - accuracy: 0.9824 - precision: 0.9876 - recall: 0.9636 - val_loss: 0.0797 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0438 - accuracy: 0.9824 - precision: 0.9876 - recall: 0.9636 - val_loss: 0.0879 - val_accuracy: 0.9561 - val_precision: 0.9375 - val_recall: 0.9574\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0369 - accuracy: 0.9890 - precision: 0.9938 - recall: 0.9758 - val_loss: 0.0751 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0358 - accuracy: 0.9868 - precision: 0.9938 - recall: 0.9697 - val_loss: 0.0723 - val_accuracy: 0.9737 - val_precision: 0.9783 - val_recall: 0.9574\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0381 - accuracy: 0.9868 - precision: 0.9877 - recall: 0.9758 - val_loss: 0.0748 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0381 - accuracy: 0.9868 - precision: 0.9877 - recall: 0.9758 - val_loss: 0.0740 - val_accuracy: 0.9737 - val_precision: 0.9783 - val_recall: 0.9574\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0392 - accuracy: 0.9868 - precision: 0.9938 - recall: 0.9697 - val_loss: 0.0755 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0365 - accuracy: 0.9890 - precision: 0.9938 - recall: 0.9758 - val_loss: 0.0754 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0355 - accuracy: 0.9846 - precision: 0.9877 - recall: 0.9697 - val_loss: 0.0703 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0338 - accuracy: 0.9912 - precision: 0.9939 - recall: 0.9818 - val_loss: 0.0742 - val_accuracy: 0.9737 - val_precision: 0.9783 - val_recall: 0.9574\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0355 - accuracy: 0.9868 - precision: 0.9877 - recall: 0.9758 - val_loss: 0.0708 - val_accuracy: 0.9737 - val_precision: 0.9783 - val_recall: 0.9574\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0400 - accuracy: 0.9824 - precision: 0.9816 - recall: 0.9697 - val_loss: 0.0683 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0329 - accuracy: 0.9868 - precision: 0.9938 - recall: 0.9697 - val_loss: 0.0656 - val_accuracy: 0.9737 - val_precision: 0.9783 - val_recall: 0.9574\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0341 - accuracy: 0.9846 - precision: 0.9937 - recall: 0.9636 - val_loss: 0.0677 - val_accuracy: 0.9737 - val_precision: 0.9783 - val_recall: 0.9574\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0297 - accuracy: 0.9890 - precision: 0.9938 - recall: 0.9758 - val_loss: 0.0689 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0371 - accuracy: 0.9846 - precision: 0.9759 - recall: 0.9818 - val_loss: 0.0664 - val_accuracy: 0.9737 - val_precision: 0.9783 - val_recall: 0.9574\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0348 - accuracy: 0.9846 - precision: 0.9937 - recall: 0.9636 - val_loss: 0.0643 - val_accuracy: 0.9737 - val_precision: 0.9783 - val_recall: 0.9574\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0324 - accuracy: 0.9912 - precision: 0.9879 - recall: 0.9879 - val_loss: 0.0632 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0292 - accuracy: 0.9890 - precision: 0.9938 - recall: 0.9758 - val_loss: 0.0667 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0285 - accuracy: 0.9890 - precision: 0.9938 - recall: 0.9758 - val_loss: 0.0651 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0328 - accuracy: 0.9868 - precision: 0.9877 - recall: 0.9758 - val_loss: 0.0647 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 0.9890 - precision: 0.9878 - recall: 0.9818 - val_loss: 0.0612 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0339 - accuracy: 0.9846 - precision: 0.9817 - recall: 0.9758 - val_loss: 0.0619 - val_accuracy: 0.9737 - val_precision: 0.9783 - val_recall: 0.9574\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0277 - accuracy: 0.9956 - precision: 1.0000 - recall: 0.9879 - val_loss: 0.0619 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0361 - accuracy: 0.9890 - precision: 0.9938 - recall: 0.9758 - val_loss: 0.0665 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0340 - accuracy: 0.9846 - precision: 0.9817 - recall: 0.9758 - val_loss: 0.0622 - val_accuracy: 0.9649 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_47 (Conv1D)          (None, 28, 128)           512       \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 28, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_39 (MaxPoolin  (None, 14, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_48 (Conv1D)          (None, 12, 64)            24640     \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 12, 64)            0         \n",
      "                                                                 \n",
      " max_pooling1d_40 (MaxPoolin  (None, 6, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_28 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 128)               49280     \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 82,753\n",
      "Trainable params: 82,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#The output of the Conv1D layer will have a shape of (batch_size, num_filters, output_dim). Since the output of the Conv1D layer is still in a multi-dimensional format, it cannot be directly connected to the subsequent Dense layers which expect one-dimensional input.\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(128, kernel_size = 3, input_shape = (30, 1) ), #Covolution1D operates on (batch size, length, channels)\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.MaxPool1D(2),\n",
    "\n",
    "    tf.keras.layers.Conv1D(64, kernel_size = 3), \n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.MaxPool1D(2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    \n",
    "    #tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    #tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "    #tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "])\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.binary_crossentropy,\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "    metrics = [\n",
    "        tf.keras.metrics.BinaryAccuracy(name = 'accuracy'),\n",
    "        tf.keras.metrics.Precision(name = 'precision'),\n",
    "        tf.keras.metrics.Recall(name = 'recall')\n",
    "    ]\n",
    ")\n",
    "validation_data=(x_test,y_test)\n",
    "history = model.fit(x_train, y_train,  epochs = 100, validation_data=validation_data)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot the results\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "f1 = f1_score(y_test, pred)\n",
    "rec = recall_score(y_test, pred)\n",
    "prec = precision_score(y_test, pred)\n",
    "conf_matrix = confusion_matrix(y_test, pred)\n",
    "\n",
    "results = pd.DataFrame([[acc, f1, rec, prec]], columns=['Accuracy score', 'F1 score', 'Recall score', 'Precision score'])\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
